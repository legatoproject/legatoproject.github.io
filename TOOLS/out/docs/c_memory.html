<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" SYSTEM "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
<title>Dynamic Memory Allocation API  - Legato Docs</title>
<meta content="legatoâ„¢ is an open source Linux-based embedded platform designed to simplify connected IoT application development" name="description" />
<meta content="#keywords" name="keywords" />
<meta content="noindex, nofollow" name="robots" />
<meta content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport" />
<link href="/resources/images/legato.ico" rel="shortcut icon" />
<link href="/resources/images/legato.ico" rel="icon" type="image/x-icon" />
<link href="/resources/images/legato.ico" rel="shortcut icon" type="image/x-icon" />
<link href="#" rel="apple-touch-icon" />
<link href="#" rel="apple-touch-icon" sizes="72x72" />
<link href="#" rel="apple-touch-icon" sizes="114x114" />
<link href="/resources/css/style.css" media="screen" rel="stylesheet" type="text/css" />
<link href="/resources/css/font-awesome.css" rel="stylesheet" type="text/css" />
<!--[if IE]>
        <script src="/resources/js/html5shiv.js"></script>
        <script src="/resources/js/respond.js"></script>
        <![endif]-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.6.2/jquery.min.js"></script>
<script src="/resources/js/main.js"></script>
<link href="/resources/css/jqtree.css" rel="stylesheet" type="text/css" />
<script src="/resources/js/tree.jquery.js" type="text/javascript"></script>
<script src="/resources/js/jquery.cookie.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.min.js"></script>
<script>
        setupTree("/resources/tocs/Build Apps Documentation.json");
        </script>
</head>
<body>
<div class="wrapper">
<div class="fa fa-bars documentation" id="menu-trigger"></div>
<div id="top">
<header>
<nav>
<a class="navlink" href="/index.html">Introduction</a><a class="navlink" href="/docs/getstarted_main.html">Build Apps</a><a class="subnavlink" href="/docs/getstarted_main.html">Get started</a><a class="subnavlink" href="/docs/build_apps_documentation.html">Documentation</a><a class="subnavlink" href="/docs/files.html">Reference</a><a class="navlink" href="/docs/platform_constraints.html">Build Platform</a><a class="subnavlink" href="/docs/platform_constraints.html">Platform Constraints</a><a class="subnavlink" href="/docs/yocto_main.html">Yocto Info</a><a class="navlink" href="/docs/about_main.html">About</a>
</nav>
</header>
</div>
<div class="orange" id="menudocumentation">
<header>
<h1><a class="navlink" href="/" title="back to Legato homepage">Legato</a></h1>
<h2>/ Build Apps</h2>
<nav class="ui-front" id="searchresult">
<i class="fa fa-search"></i>
<input id="autocomplete" onkeyup="getdata('Build Apps')" placeholder="Search..." /> <!-- <input id="category" type="checkbox" onclick="checkbox()"> <label for="category">API Search</label> -->
</nav>
</header>
</div>
<div class="orange" id="topMenu">
<nav>
<a href="getstarted_main.html">Get Started</a><a class="link-selected" href="build_apps_documentation.html">Documentation</a><a href="files.html">Reference</a>
</nav>
</div>
<div id="left">
<div id="tree1"></div>
</div>
<div class="content">
<div class="header">
<div class="headertitle">
<h1 class="title">Dynamic Memory Allocation API </h1> </div>
</div><div class="contents">
<div class="textblock"><p><a class="el" href="le__mem_8h.html">API Reference</a></p>
<hr />
<p>Dynamic memory allocation (especially deallocation) using the C runtime heap, through malloc, free, strdup, calloc, realloc, etc. can result in performance degradation and out-of-memory conditions.</p>
<p>This is due to fragmentation of the heap. The degraded performance and exhausted memory result from indirect interactions within the heap between unrelated application code. These issues are non-deterministic, and can be very difficult to rectify.</p>
<p>Memory Pools offer a powerful solution. They trade-off a deterministic amount of memory for</p><ul>
<li>deterministic behaviour,</li>
<li>O(1) allocation and release performance, and</li>
<li>built-in memory allocation tracking.</li>
</ul>
<p>And it brings the power of <b>destructors</b> to C!</p>
<h1><a class="anchor" id="mem_overview"></a>
Overview</h1>
<p>The most basic usage involves:</p><ul>
<li>Creating a pool (usually done once at process start-up)</li>
<li>Allocating objects (memory blocks) from a pool</li>
<li>Releasing objects back to their pool.</li>
</ul>
<p>Pools generally can't be deleted. You create them when your process starts-up, and use them until your process terminates. It's up to the OS to clean-up the memory pools, along with everything else your process is using, when your process terminates. (Although, if you find yourself really needing to delete pools, <a class="el" href="c_memory.html#mem_sub_pools">Sub-Pools</a> could offer you a solution.)</p>
<p>Pools also support the following advanced features:</p><ul>
<li>reference counting</li>
<li>destructors</li>
<li>statistics</li>
<li>multi-threading</li>
<li>sub-pools (pools that can be deleted).</li>
</ul>
<p>The following sections describe these, beginning with the most basic usage and working up to more advanced topics.</p>
<h1><a class="anchor" id="mem_creating"></a>
Creating a Pool</h1>
<p>Before allocating memory from a pool, the pool must be created using <a class="el" href="le__mem_8h.html#ab91efaa2978c9c1c7b2427d25b33241c">le_mem_CreatePool()</a>, passing it the name of the pool and the size of the objects to be allocated from that pool. This returns a reference to the new pool, which has zero free objects in it.</p>
<p>To populate your new pool with free objects, you call <code><a class="el" href="le__mem_8h.html#a79a4321ffa0345f267eaf3b7d3d3528a">le_mem_ExpandPool()</a></code>. This is separated into two functions (rather than having one function with three parameters) to make it virtually impossible to accidentally get the parameters in the wrong order (which would result in nasty bugs that couldn't be caught by the compiler). The ability to expand pools comes in handy (see <a class="el" href="c_memory.html#mem_pool_sizes">Managing Pool Sizes</a>).</p>
<p>This code sample defines a class "Point" and a pool "PointPool" used to allocate memory for objects of that class: </p><div class="fragment"><div class="line"><span class="preprocessor">#define MAX_POINTS 12  // Maximum number of points that can be handled.</span></div><div class="line"></div><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span></div><div class="line">{</div><div class="line"> <span class="keywordtype">int</span> x;  <span class="comment">// pixel position along x-axis</span></div><div class="line"> <span class="keywordtype">int</span> y;  <span class="comment">// pixel position along y-axis</span></div><div class="line">}</div><div class="line">Point_t;</div><div class="line"></div><div class="line">le_mem_PoolRef_t PointPool;</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> xx_pt_ProcessStart(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    PointPool = <a class="code" href="le__mem_8h.html#ab91efaa2978c9c1c7b2427d25b33241c">le_mem_CreatePool</a>(<span class="stringliteral">"xx.pt.Points"</span>, <span class="keyword">sizeof</span>(Point_t));</div><div class="line"> <a class="code" href="le__mem_8h.html#a79a4321ffa0345f267eaf3b7d3d3528a">le_mem_ExpandPool</a>(PointPool, MAX_POINTS);</div><div class="line"></div><div class="line"> <span class="keywordflow">return</span> SUCCESS;</div><div class="line">}</div></div><!-- fragment --><p>To make things easier for power-users, <code><a class="el" href="le__mem_8h.html#a79a4321ffa0345f267eaf3b7d3d3528a">le_mem_ExpandPool()</a></code> returns the same pool reference that it was given. This allows the xx_pt_ProcessStart() function to be re-implemented as follows: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> xx_pt_ProcessStart(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    PointPool = <a class="code" href="le__mem_8h.html#a79a4321ffa0345f267eaf3b7d3d3528a">le_mem_ExpandPool</a>(<a class="code" href="le__mem_8h.html#ab91efaa2978c9c1c7b2427d25b33241c">le_mem_CreatePool</a>(<span class="keyword">sizeof</span>(Point_t)), MAX_POINTS);</div><div class="line"></div><div class="line"> <span class="keywordflow">return</span> SUCCESS;</div><div class="line">}</div></div><!-- fragment --><p>Although this requires a dozen or so fewer keystrokes of typing and occupies one less line of code, it's arguably less readable than the previous example.</p>
<p>For a discussion on how to pick the number of objects to have in your pools, see <a class="el" href="c_memory.html#mem_pool_sizes">Managing Pool Sizes</a>.</p>
<h1><a class="anchor" id="mem_allocating"></a>
Allocating From a Pool</h1>
<p>Allocating from a pool has multiple options:</p><ul>
<li><code><a class="el" href="le__mem_8h.html#a742e4f9d621ca27493733ca781bbe187">le_mem_TryAlloc()</a></code> - Quietly return NULL if there are no free blocks in the pool.</li>
<li><code><a class="el" href="le__mem_8h.html#a2993bf7a9705d119c96cf80cd64a56bb">le_mem_AssertAlloc()</a></code> - Log an error and take down the process if there are no free blocks in the pool.</li>
<li><code><a class="el" href="le__mem_8h.html#af7c289c73d4182835a26a9099f3db359">le_mem_ForceAlloc()</a></code> - If there are no free blocks in the pool, log a warning and automatically expand the pool (or log an error and terminate the calling process there's not enough free memory to expand the pool).</li>
</ul>
<p>All of these functions take a pool reference and return a pointer to the object allocated from the pool.</p>
<p>The first option, using <code><a class="el" href="le__mem_8h.html#a742e4f9d621ca27493733ca781bbe187">le_mem_TryAlloc()</a></code>, is the closest to the way good old malloc() works. It requires the caller check the return code to see if it's NULL. This can be annoying enough that a lot of people get lazy and don't check the return code (Bad programmer! Bad!). It turns out that this option isn't really what people usually want (but occasionally they do)</p>
<p>The second option, using <code><a class="el" href="le__mem_8h.html#a2993bf7a9705d119c96cf80cd64a56bb">le_mem_AssertAlloc()</a></code>, is only used when the allocation should never fail, by design; a failure to allocate a block is a fatal error. This isn't often used, but can save a lot of boilerplate error checking code.</p>
<p>The third option, <code>using</code> <a class="el" href="le__mem_8h.html#af7c289c73d4182835a26a9099f3db359">le_mem_ForceAlloc()</a>, is the one that gets used most often. It allows developers to avoid writing error checking code, because the allocation will essentially never fail because it's handled inside the memory allocator. It also allows developers to defer fine tuning their pool sizes until after they get things working. Later, they check the logs for pool size usage, and then modify their pool sizes accordingly. If a particular pool is continually growing, it's a good indication there's a memory leak. This permits seeing exactly what objects are being leaked. If certain debug options are turned on, they can even find out which line in which file allocated the blocks being leaked.</p>
<h1><a class="anchor" id="mem_releasing"></a>
Releasing Back Into a Pool</h1>
<p>Releasing memory back to a pool never fails, so there's no need to check a return code. Also, each object knows which pool it came from, so the code that releases the object doesn't have to care. All it has to do is call <code><a class="el" href="le__mem_8h.html#a6d8e3fe430bcb81efe97b57ce30ef2de">le_mem_Release()</a></code> and pass a pointer to the object to be released.</p>
<p>The critical thing to remember is that once an object has been released, it <b> must never be accessed again </b>. Here is a <b> very bad code example</b>: </p><div class="fragment"><div class="line">Point_t* pointPtr = <a class="code" href="le__mem_8h.html#af7c289c73d4182835a26a9099f3db359">le_mem_ForceAlloc</a>(PointPool);</div><div class="line">pointPtr->x = 5;</div><div class="line">pointPtr->y = 10;</div><div class="line"><a class="code" href="le__mem_8h.html#a6d8e3fe430bcb81efe97b57ce30ef2de">le_mem_Release</a>(pointPtr);</div><div class="line">printf(<span class="stringliteral">"Point is at position (%d, %d).\n"</span>, pointPtr->x, pointPtr->y);</div></div><!-- fragment --><h1><a class="anchor" id="mem_ref_counting"></a>
Reference Counting</h1>
<p>Reference counting is a powerful feature of our memory pools. Here's how it works:</p><ul>
<li>Every object allocated from a pool starts with a reference count of 1.</li>
<li>Whenever someone calls <a class="el" href="le__mem_8h.html#a92e869f92a344d61fb44922f99fe679b">le_mem_AddRef()</a> on an object, its reference count is incremented by 1.</li>
<li>When it's released, its reference count is decremented by 1.</li>
<li>When its reference count reaches zero, it's destroyed (i.e., its memory is released back into the pool.)</li>
</ul>
<p>This allows one function to:</p><ul>
<li>create an object.</li>
<li>work with it.</li>
<li>increment its reference count and pass a pointer to the object to another function (or thread, data structure, etc.).</li>
<li>work with it some more.</li>
<li>release the object without having to worry about when the other function is finished with it.</li>
</ul>
<p>The other function also releases the object when it's done with it. So, the object will exist until both functions are done.</p>
<p>If there are multiple threads involved, be careful to protect the shared object from race conditions(see the <a class="el" href="c_memory.html#mem_threading">Multi-Threading</a>).</p>
<p>Another great advantage of reference counting is it enables <a class="el" href="c_memory.html#mem_destructors">Destructors</a>.</p>
<h1><a class="anchor" id="mem_destructors"></a>
Destructors</h1>
<p>Destructors are a powerful feature of C++. Anyone who has any non-trivial experience with C++ has used them. Because C was created before object-oriented programming was around, there's no native language support for destructors in C. Object-oriented design is still possible and highly desireable even when the programming is done in C.</p>
<p>In Legato, it's possible to call <code><a class="el" href="le__mem_8h.html#a055007b38ce04bcb823e08034fd11b85">le_mem_SetDestructor()</a></code> to attach a function to a memory pool to be used as a destructor for objects allocated from that pool. If a pool has a destructor, whenever the reference count reaches zero for an object allocated from that pool, the pool's destructor function will pass a pointer to that object. After the destructor returns, the object will be fully destroyed, and its memory will be released back into the pool for later reuse by another object.</p>
<p>Here's a destructor code sample: </p><div class="fragment"><div class="line"><span class="keyword">static</span> <span class="keywordtype">void</span> PointDestructor(<span class="keywordtype">void</span>* objPtr)</div><div class="line">{</div><div class="line">    Point_t* pointPtr = objPtr;</div><div class="line"></div><div class="line">    printf(<span class="stringliteral">"Destroying point (%d, %d)\n"</span>, pointPtr->x, pointPtr->y);</div><div class="line"></div><div class="line">    @todo Add more to sample.</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> xx_pt_ProcessStart(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    PointPool = <a class="code" href="le__mem_8h.html#ab91efaa2978c9c1c7b2427d25b33241c">le_mem_CreatePool</a>(<span class="keyword">sizeof</span>(Point_t));</div><div class="line"> <a class="code" href="le__mem_8h.html#a79a4321ffa0345f267eaf3b7d3d3528a">le_mem_ExpandPool</a>(PointPool, MAX_POINTS);</div><div class="line"> <a class="code" href="le__mem_8h.html#a055007b38ce04bcb823e08034fd11b85">le_mem_SetDestructor</a>(PointPool, PointDestructor);</div><div class="line"> <span class="keywordflow">return</span> SUCCESS;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">static</span> <span class="keywordtype">void</span> DeletePointList(Point_t** pointList, <span class="keywordtype">size_t</span> numPoints)</div><div class="line">{</div><div class="line"> <span class="keywordtype">size_t</span> i;</div><div class="line"> <span class="keywordflow">for</span> (i = 0; i < numPoints; i++)</div><div class="line">    {</div><div class="line"> <a class="code" href="le__mem_8h.html#a6d8e3fe430bcb81efe97b57ce30ef2de">le_mem_Release</a>(pointList[i]);</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>In this sample, when DeletePointList() is called (with a pointer to an array of pointers to Point_t objects with reference counts of 1), each of the objects in the pointList is released. This causes their reference counts to hit 0, which triggers executing PointDestructor() for each object in the pointList, and the "Destroying point..." message will be printed for each.</p>
<h1><a class="anchor" id="mem_stats"></a>
Statistics</h1>
<p>Some statistics are gathered for each memory pool:</p><ul>
<li>Number of allocations.</li>
<li>Number of currently free objects.</li>
<li>Number of overflows (times that <a class="el" href="le__mem_8h.html#af7c289c73d4182835a26a9099f3db359">le_mem_ForceAlloc()</a> had to expand the pool).</li>
</ul>
<p>Statistics (and other pool properties) can be checked using functions:</p><ul>
<li><code><a class="el" href="le__mem_8h.html#ab7b41431c57c8c7b5c4ff1501fd5b772">le_mem_GetStats()</a></code> </li>
<li><code><a class="el" href="le__mem_8h.html#a76725588ed757ca95cdf36e5ab3aeebf">le_mem_GetObjectCount()</a></code> </li>
<li><code><a class="el" href="le__mem_8h.html#a0f6fbc0c886486a1e19fc43143991c66">le_mem_GetObjectSize()</a></code> </li>
</ul>
<p>Statistics are fetched together atomically using a single function call. This prevents inconsistencies between them if in a multi-threaded program.</p>
<p>If you don't have a reference to a specified pool, but you have the name of the pool, you can get a reference to the pool using <code><a class="el" href="le__mem_8h.html#a67e004702344963aea788b1c0ca70862">le_mem_FindPool()</a></code>.</p>
<p>In addition to programmatically fetching these, they're also available through the "poolstat" console command (unless your process's main thread is blocked).</p>
<p>To reset the pool statistics, use <code><a class="el" href="le__mem_8h.html#a35b7e757356764c39f0a7ede2aa242ae">le_mem_ResetStats()</a></code>.</p>
<h1><a class="anchor" id="mem_diagnostics"></a>
Diagnostics</h1>
<p>The memory system also supports two different forms of diagnostics. Both are enabled by defining special preprocessor macros when building the framework.</p>
<p>The first of which is <code>LE_MEM_TRACE</code>. When you define <code>LE_MEM_TRACE</code> every pool is given a tracepoint with the name of the pool on creation.</p>
<p>For instance, the configTree node pool is called, "configTree.nodePool". So to enable a trace of all config tree node creation and deletion one would use the log tool as follows:</p>
<div class="fragment"><div class="line">$ log trace configTree.nodePool</div></div><!-- fragment --><p>The second diagnostic build flag is <code>LE_MEM_VALGRIND</code>. When <code>LE_MEM_VALGRIND</code> is enabled, the pools are disabled and instead malloc and free are directly used. Thus enabling the use of tools like Valgrind.</p>
<h1><a class="anchor" id="mem_threading"></a>
Multi-Threading</h1>
<p>All functions in this API are <b> thread-safe, but not async-safe </b>. The objects allocated from pools are not inherently protected from races between threads.</p>
<p>Allocating and releasing objects, checking stats, incrementing reference counts, etc. can all be done from multiple threads (excluding signal handlers) without having to worry about corrupting the memory pools' hidden internal data structures.</p>
<p>There's no magical way to prevent different threads from interferring with each other if they both access the <em>contents</em> of the same object at the same time.</p>
<p>The best way to prevent multi-threaded race conditions is simply don't share data between threads. If multiple threads must access the same data structure, then mutexes, semaphores, or similar methods should be used to <em>synchronize</em> threads and avoid data structure corruption or thread misbehaviour.</p>
<p>Although memory pools are <em>thread-safe</em>, they are not <em>async-safe</em>. This means that memory pools <em>can</em> be corrupted if they are accessed by a signal handler while they are being accessed by a normal thread. To be safe, <b> don't call any memory pool functions from within a signal handler. </b></p>
<p>One problem using destructor functions in a multi-threaded environment is that the destructor function modifies a data structure shared between threads, so it's easy to forget to synchronize calls to <code><a class="el" href="le__mem_8h.html#a6d8e3fe430bcb81efe97b57ce30ef2de">le_mem_Release()</a></code> with other code accessing the data structure. If a mutex is used to coordinate access to the data structure, then the mutex must be held by the thread that calls <a class="el" href="le__mem_8h.html#a6d8e3fe430bcb81efe97b57ce30ef2de">le_mem_Release()</a> to ensure there's no other thread accessing the data structure when the destructor runs.</p>
<h1><a class="anchor" id="mem_pool_sizes"></a>
Managing Pool Sizes</h1>
<p>We know it's possible to have pools automatically expand when they are exhausted, but we don't really want that to happen normally. Ideally, the pools should be fully allocated to their maximum sizes at start-up so there aren't any surprises later when certain feature combinations cause the system to run out of memory in the field. If we allocate everything we think is needed up-front, then we are much more likely to uncover any memory shortages during testing, before it's in the field.</p>
<p>Choosing the right size for your pools correctly at start-up is easy to do if there is a maximum number of fixed, external <em>things</em> that are being represented by the objects being allocated from the pool. If the pool holds "call objects" representing phone calls over a T1 carrier that will never carry more than 24 calls at a time, then it's obvious that you need to size your call object pool at 24.</p>
<p>Other times, it's not so easy to choose the pool size like code to be reused in different products or different configurations that have different needs. In those cases, you still have a few options:</p>
<ul>
<li>At start-up, query the operating environment and base the pool sizes.</li>
<li>Read a configuration setting from a file or other configuration data source.</li>
<li>Use a build-time configuration setting.</li>
</ul>
<p>The build-time configuration setting is the easiest, and generally requires less interaction between components at start-up simplifying APIs and reducing boot times.</p>
<p>If the pool size must be determined at start-up, use <code><a class="el" href="le__mem_8h.html#a79a4321ffa0345f267eaf3b7d3d3528a">le_mem_ExpandPool()</a></code>. Perhaps there's a service-provider module designed to allocate objects on behalf of client. It can have multiple clients at the same time, but it doesn't know how many clients or what their resource needs will be until the clients register with it at start-up. We'd want those clients to be as decoupled from each other as possible (i.e., we want the clients know as little as possible about each other); we don't want the clients to get together and add up all their needs before telling the service-provider. We'd rather have the clients independently report their own needs to the service-provider. Also, we don't want each client to have to wait for all the other clients to report their needs before starting to use the services offered by the service-provider. That would add more complexity to the interactions between the clients and the service-provider.</p>
<p>This is what should happen when the service-provider can't wait for all clients to report their needs before creating the pool:</p><ul>
<li>When the service-provider starts up, it creates an empty pool.</li>
<li>Whenever a client registers itself with the service-provider, the client can tell the service-provider what its specific needs are, and the service-provider can expand its object pool accordingly.</li>
<li>Since registrations happen at start-up, pool expansion occurs at start-up, and testing will likely find any pool sizing before going into the field.</li>
</ul>
<p>Where clients dynamically start and stop during runtime in response to external events (e.g., when someone is using the device's Web UI), we still have a problem because we can't <em>shrink</em> pools or delete pools when clients go away. This is where <a class="el" href="c_memory.html#mem_sub_pools">Sub-Pools</a> is useful.</p>
<h1><a class="anchor" id="mem_sub_pools"></a>
Sub-Pools</h1>
<p>Essentially, a Sub-Pool is a memory pool that gets its blocks from another pool (the super-pool). Sub Pools <em>can</em> be deleted, causing its blocks to be released back into the super-pool.</p>
<p>This is useful when a service-provider module needs to handle clients that dynamically pop into existence and later disappear again. When a client attaches to the service and says it will probably need a maximum of X of the service-provider's resources, the service provider can set aside that many of those resources in a sub-pool for that client. If that client goes over its limit, the sub-pool will log a warning message.</p>
<p>The problem of sizing the super-pool correctly at start-up still exists, so what's the point of having a sub-pool, when all of the resources could just be allocated from the super-pool?</p>
<p>The benefit is really gained in troubleshooting. If client A, B, C, D and E are all behaving nicely, but client F is leaking resources, the sub-pool created on behalf of client F will start warning about the memory leak; time won't have to be wasted looking at clients A through E to rule them out.</p>
<p>To create a sub-pool, call <code><a class="el" href="le__mem_8h.html#a8b043fcb013deb4c58c90ca2e0ab9d16">le_mem_CreateSubPool()</a></code>. It takes a reference to the super-pool and the objects specified to the sub-pool, and it returns a reference to the new sub-pool.</p>
<p>To delete a sub-pool, call <code><a class="el" href="le__mem_8h.html#aa1d51a37f572c2d891cdfb625ea19f27">le_mem_DeleteSubPool()</a></code>. Do not try to use it to delete a pool that was created using <a class="el" href="le__mem_8h.html#ab91efaa2978c9c1c7b2427d25b33241c">le_mem_CreatePool()</a>. It's only for sub-pools created using <a class="el" href="le__mem_8h.html#a8b043fcb013deb4c58c90ca2e0ab9d16">le_mem_CreateSubPool()</a>. Also, it's <b>not</b> okay to delete a sub-pool while there are still blocks allocated from it. You'll see errors in your logs if you do that.</p>
<p>Sub-Pools automatically inherit their parent's destructor function.</p>
<dl class="section note"><dt>Note</dt><dd>You can't create sub-pools of sub-pools (i.e., sub-pools that get their blocks from another sub-pool).</dd></dl>
<hr />
<p class="copyright">Copyright (C) Sierra Wireless Inc. Use of this work is subject to license. </p>
</div></div>
<br clear="left" />
</div>
<div id="footer">
</div>
</div>
</body>
</html>